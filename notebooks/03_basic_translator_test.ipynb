{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a32287",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks//data//raw//tibetan_english_sample.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m os.makedirs(\u001b[33m'\u001b[39m\u001b[33mnotebooks/data/processed\u001b[39m\u001b[33m'\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Build the dictionary\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mbuild_dictionary_from_parallel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Now load the parallel data for testing\u001b[39;00m\n\u001b[32m     29\u001b[39m df = load_parallel_data(input_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91770\\tibetan-english-translator\\notebooks\\..\\src\\build_dictionary.py:7\u001b[39m, in \u001b[36mbuild_dictionary_from_parallel_data\u001b[39m\u001b[34m(input_file, output_file)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build a simple dictionary from parallel text data\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load the parallel data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mload_parallel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Initialize tokenizers\u001b[39;00m\n\u001b[32m     10\u001b[39m tib_tokenizer = TibetanTokenizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91770\\tibetan-english-translator\\notebooks\\..\\src\\data_loader.py:10\u001b[39m, in \u001b[36mload_parallel_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mLoad parallel text data from a tab-separated file\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03mReturns a pandas DataFrame with Tibetan and English columns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m data = []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m line.strip():  \u001b[38;5;66;03m# Skip empty lines\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'notebooks//data//raw//tibetan_english_sample.txt'"
     ]
    }
   ],
   "source": [
    "# Basic Tibetan-English Translator Test\n",
    "#\n",
    "# This notebook demonstrates our simple dictionary-based translator\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add parent directory to path so we can import our modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our modules\n",
    "from src.data_loader import load_parallel_data\n",
    "from src.dictionary import TibetanEnglishDictionary\n",
    "from src.translator import BasicTranslator\n",
    "from src.build_dictionary import build_dictionary_from_parallel_data\n",
    "\n",
    "# First, let's build our dictionary from sample data\n",
    "input_file = '../data/raw/tibetan_english_sample.txt'\n",
    "output_file = '../data/processed/simple_dictionary.txt'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Build the dictionary\n",
    "build_dictionary_from_parallel_data(input_file, output_file)\n",
    "\n",
    "# Now load the parallel data for testing\n",
    "df = load_parallel_data(input_file)\n",
    "\n",
    "# Create a translator\n",
    "translator = BasicTranslator(dictionary_path=output_file)\n",
    "\n",
    "# Try translating each example\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    tibetan = row['tibetan']\n",
    "    actual_english = row['english']\n",
    "    \n",
    "    # Translate Tibetan to English\n",
    "    translated_english = translator.translate_tibetan_to_english(tibetan)\n",
    "    \n",
    "    # Translate English to Tibetan\n",
    "    translated_tibetan = translator.translate_english_to_tibetan(actual_english)\n",
    "    \n",
    "    results.append({\n",
    "        'original_tibetan': tibetan,\n",
    "        'actual_english': actual_english,\n",
    "        'translated_english': translated_english,\n",
    "        'translated_tibetan': translated_tibetan\n",
    "    })\n",
    "\n",
    "# Show the results\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
